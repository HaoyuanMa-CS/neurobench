{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGm4fad3M-Sr"
      },
      "source": [
        "# Mackey Glass Benchmark Tutorial\n",
        "\n",
        "This tutorial aims to provide an insight on how the NeuroBench framework is organized and how you can use it to benchmark your own models!\n",
        "\n",
        "## About Mackey Glass:\n",
        "\n",
        "### Dataset:\n",
        "The Mackey Glass task is a chaotic function prediction task. Contrary to the other tasks in NeuroBench, the Mackey Glass dataset is synthetic. Real-world data can be high-dimensional and require large networks to achieve high accuracy, presenting challenges for solution types with limited I/O support and network capacity, such as mixed-signal prototype solutions. The Mackey Glass dataset is a one-dimensional non-linear time delay differential equation, where the evoluiton of the signal can be altered by a number of different parameters. These parameters are defined in NeuroBench. \n",
        "<!-- $$ dx \\over dt = \\beta {x(t-\\tau)} \\over {1 + x(t-\\tau)^n} - \\gamma x(t)\n",
        "$$ -->\n",
        "$$ \\frac{dx}{dt} = \\frac{\\beta x(t-\\tau)}{1 + x(t-\\tau)^n} - \\gamma x(t) $$\n",
        "\n",
        "### Benchmark Task:\n",
        "The task is a sequence-to-sequence prediction problem, similar to the primate reaching task, included in NeuroBench. The input sequence x is used to predict the future values of the same sequence, y(t) = x(t). The input data is passed at a timestep of $\\Delta$ t, and the performance of the system is be tested in a multi-horizon prediction setting, where future values of the sequence are predicted at a rate of $\\Delta$ t. The taskâ€™s difficulty is be varied by adjusting the ratio between the integration time step $\\Delta$ t and the timescale $\\tau$ of the underlying dynamics.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "First we will import the relevant libraries. These include the datasets, preprocessors and accumulators. To ensure your model to be compatible with the NeuroBench framework, we will import the wrapper for snnTorch models. This wrapper will not change your model. Finally, we import the Benchmark class, which will run the benchmark and calculate your metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqtM6XbMM_hO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from neurobench.datasets import MackeyGlass\n",
        "from neurobench.models import TorchModel\n",
        "from neurobench.benchmarks import Benchmark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7HMjVPX7LZh"
      },
      "source": [
        "For this tutorial, we will make use of the example architecture that is included in the NeuroBench framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r0yYDNRZ7UxY"
      },
      "outputs": [],
      "source": [
        "# this is the network we will be using in this tutorial\n",
        "from neurobench.examples.mackey_glass.echo_state_network import EchoStateNetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIgTfvuOMe-"
      },
      "source": [
        "The Mackey Glass task is a synthetic dataset that is generated upon calling the MackeyGlass function. The parameters of the Mackey Glass function have to be passed by the user. These parameters define the output sequence that is generated. The NeuroBench framework provides the parameters that can be used for obtaining the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chZeyUTAOQ6B"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/data/speech_commands/tmpy8couawl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/GSC_tutorial.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/GSC_tutorial.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_set \u001b[39m=\u001b[39m SpeechCommands(path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/speech_commands/\u001b[39;49m\u001b[39m\"\u001b[39;49m, subset\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtesting\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/GSC_tutorial.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_set_loader \u001b[39m=\u001b[39m DataLoader(test_set, batch_size\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/NeuroBench/algorithms_benchmarks/neurobench/datasets/__init__.py:5\u001b[0m, in \u001b[0;36mSpeechCommands\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSpeechCommands\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m _lazy_import(\u001b[39m\"\u001b[39;49m\u001b[39mneurobench.datasets\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m.speech_commands\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mSpeechCommands\u001b[39;49m\u001b[39m\"\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/NeuroBench/algorithms_benchmarks/neurobench/datasets/speech_commands.py:21\u001b[0m, in \u001b[0;36mSpeechCommands.__init__\u001b[0;34m(self, path, subset, truncate_or_pad_to_1s)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, path, subset:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, truncate_or_pad_to_1s\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, ):\n\u001b[1;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Initializes the SpeechCommands dataset.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m        truncate_or_pad_to_1s (bool, optional): whether to truncate or pad samples to 1s. Defaults to True.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     SPEECHCOMMANDS\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, path, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, subset\u001b[39m=\u001b[39;49msubset)\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtruncate_or_pad_to_1s \u001b[39m=\u001b[39m truncate_or_pad_to_1s\n\u001b[1;32m     24\u001b[0m     \u001b[39m# convert labels to indices\u001b[39;00m\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/neurobench--0oLx93m-py3.10/lib/python3.10/site-packages/torchaudio/datasets/speechcommands.py:109\u001b[0m, in \u001b[0;36mSPEECHCOMMANDS.__init__\u001b[0;34m(self, root, url, folder_in_archive, download, subset)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(archive):\n\u001b[1;32m    108\u001b[0m             checksum \u001b[39m=\u001b[39m _CHECKSUMS\u001b[39m.\u001b[39mget(url, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 109\u001b[0m             download_url_to_file(url, archive, hash_prefix\u001b[39m=\u001b[39;49mchecksum)\n\u001b[1;32m    110\u001b[0m         _extract_tar(archive, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path)\n\u001b[1;32m    111\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/neurobench--0oLx93m-py3.10/lib/python3.10/site-packages/torch/hub.py:625\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    623\u001b[0m dst \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(dst)\n\u001b[1;32m    624\u001b[0m dst_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(dst)\n\u001b[0;32m--> 625\u001b[0m f \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39;49mNamedTemporaryFile(delete\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39mdir\u001b[39;49m\u001b[39m=\u001b[39;49mdst_dir)\n\u001b[1;32m    627\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39mif\u001b[39;00m hash_prefix \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/lib/python3.10/tempfile.py:698\u001b[0m, in \u001b[0;36mNamedTemporaryFile\u001b[0;34m(mode, buffering, encoding, newline, suffix, prefix, dir, delete, errors)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[39mreturn\u001b[39;00m fd\n\u001b[1;32m    697\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 698\u001b[0m     file \u001b[39m=\u001b[39m _io\u001b[39m.\u001b[39;49mopen(\u001b[39mdir\u001b[39;49m, mode, buffering\u001b[39m=\u001b[39;49mbuffering,\n\u001b[1;32m    699\u001b[0m                     newline\u001b[39m=\u001b[39;49mnewline, encoding\u001b[39m=\u001b[39;49mencoding, errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    700\u001b[0m                     opener\u001b[39m=\u001b[39;49mopener)\n\u001b[1;32m    701\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m         raw \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(file, \u001b[39m'\u001b[39m\u001b[39mbuffer\u001b[39m\u001b[39m'\u001b[39m, file)\n",
            "File \u001b[0;32m/usr/lib/python3.10/tempfile.py:695\u001b[0m, in \u001b[0;36mNamedTemporaryFile.<locals>.opener\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopener\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[1;32m    694\u001b[0m     \u001b[39mnonlocal\u001b[39;00m name\n\u001b[0;32m--> 695\u001b[0m     fd, name \u001b[39m=\u001b[39m _mkstemp_inner(\u001b[39mdir\u001b[39;49m, prefix, suffix, flags, output_type)\n\u001b[1;32m    696\u001b[0m     \u001b[39mreturn\u001b[39;00m fd\n",
            "File \u001b[0;32m/usr/lib/python3.10/tempfile.py:395\u001b[0m, in \u001b[0;36m_mkstemp_inner\u001b[0;34m(dir, pre, suf, flags, output_type)\u001b[0m\n\u001b[1;32m    393\u001b[0m _sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mtempfile.mkstemp\u001b[39m\u001b[39m\"\u001b[39m, file)\n\u001b[1;32m    394\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m     fd \u001b[39m=\u001b[39m _os\u001b[39m.\u001b[39;49mopen(file, flags, \u001b[39m0o600\u001b[39;49m)\n\u001b[1;32m    396\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[39mcontinue\u001b[39;00m    \u001b[39m# try again\u001b[39;00m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/data/speech_commands/tmpy8couawl'"
          ]
        }
      ],
      "source": [
        "# Mackey Glass parameters\n",
        "mg_parameters_file=\"neurobench/datasets/mackey_glass_parameters.csv\"\n",
        "mg_parameters = pd.read_csv(mg_parameters_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTB808RoNXqL"
      },
      "source": [
        "Next, lwe load the hyperparameters of the echo state networks that are found via random search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4jOfnt6OeIH"
      },
      "outputs": [],
      "source": [
        "esn_parameters = pd.read_csv(\"echo_state_network_hyperparameters.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfRfdvXvOqRP"
      },
      "source": [
        "No preprocessors are used in this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GHY8vTROwzP"
      },
      "outputs": [],
      "source": [
        "preprocessors = []\n",
        "postprocessors = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9doNsI0O0Jl"
      },
      "source": [
        "The Mackey Glass task contains 14 series with varying complexity. Every series is ran a number of times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDUczVTkPOsQ"
      },
      "outputs": [],
      "source": [
        "# benchmark run over 14 different series\n",
        "sMAPE_scores = []\n",
        "\n",
        "# Number of simulations to run for each time series\n",
        "repeat = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXQYfiJpPTZb"
      },
      "source": [
        "We shift the time series by 0.5 of its Lyapunov times for each independent run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0_N96ADPeO5"
      },
      "outputs": [],
      "source": [
        "# Shift time series by 0.5 of its Lyapunov times for each independent run \n",
        "start_offset_range = torch.arange(0., 0.5*repeat, 0.5) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ytLJ-dUPp0b"
      },
      "source": [
        "With everything set up, we are ready to start the benchmark. Remember that we repeat the simulation of 14 timeseries, 10 times. We therefore need to loop through every timeseries, 10 times. \n",
        "At every run, we start by creating the dataset, and training a model. The remaining steps are similar to the examples which can be found in other notebooks such as the DVSGesture notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ldww7kiYPsU2"
      },
      "outputs": [],
      "source": [
        "for repeat_id in range(repeat):\n",
        "    for series_id in range(len(mg_parameters)):\n",
        "        tau = mg_parameters.tau[series_id]\n",
        "\n",
        "        # Load data using the parameters loaded from the csv file\n",
        "        mg = MackeyGlass(tau = tau, \n",
        "                         lyaptime = mg_parameters.lyapunov_time[series_id],\n",
        "                         constant_past = mg_parameters.initial_condition[series_id],\n",
        "                         start_offset=start_offset_range[repeat_id].item(),\n",
        "                         bin_window=1)\n",
        "\n",
        "        # Split test and train set\n",
        "        train_set = Subset(mg, mg.ind_train)\n",
        "        test_set = Subset(mg, mg.ind_test)\n",
        "        \n",
        "        # Index of the hyperparamters for the current time-series\n",
        "        ind_tau = esn_parameters.index[esn_parameters['tau'] == tau].tolist()[0]\n",
        "    \n",
        "        ## Fitting Model ##\n",
        "        seed_id = repeat_id\n",
        "\n",
        "        # Load the model with the parameters loaded from esn_parameters\n",
        "        esn = EchoStateNetwork(in_channels=1, \n",
        "            reservoir_size = esn_parameters['reservoir_size'][ind_tau], \n",
        "            input_scale = torch.tensor([esn_parameters['scale_bias'][ind_tau], esn_parameters['scale_input'][ind_tau],],dtype = torch.float64), \n",
        "            connect_prob = esn_parameters['connect_prob'][ind_tau], \n",
        "            spectral_radius = esn_parameters['spectral_radius'][ind_tau],\n",
        "            leakage = esn_parameters['leakage'][ind_tau], \n",
        "            ridge_param = esn_parameters['ridge_param'][ind_tau],\n",
        "            seed_id = seed_id )\n",
        "\n",
        "        esn.train()\n",
        "        train_data, train_labels = train_set[:] # outputs (batch, bin_window, 1)\n",
        "        warmup = 0.6 # in Lyapunov times\n",
        "        warmup_pts = round(warmup*mg.pts_per_lyaptime)\n",
        "        train_labels = train_labels[warmup_pts:]\n",
        "        esn.fit(train_data, train_labels, warmup_pts)\n",
        "        # save the model for later use\n",
        "        torch.save(esn, 'neurobench/examples/mackey_glass/model_data/esn.pth')\n",
        "         \n",
        "        ## Load Model ##\n",
        "        net = torch.load('neurobench/examples/mackey_glass/model_data/esn.pth')\n",
        "        test_set_loader = DataLoader(test_set, batch_size=mg.testtime_pts, shuffle=False)\n",
        "\n",
        "        # Wrap the model\n",
        "        model = TorchModel(net)\n",
        "    \n",
        "        static_metrics = [\"model_size\", \"connection_sparsity\"]\n",
        "        data_metrics = [\"sMAPE\", \"activation_sparsity\"]\n",
        "    \n",
        "        benchmark = Benchmark(model, test_set_loader, [], [], [static_metrics, data_metrics]) \n",
        "        results = benchmark.run()\n",
        "        print(results)\n",
        "        sMAPE_scores.append(results[\"sMAPE\"])\n",
        "\n",
        "print(\"Average sMAPE score accross all repeats and time series: \", sum(sMAPE_scores)/len(sMAPE_scores))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
