{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGm4fad3M-Sr"
      },
      "source": [
        "# Google Speech Commands Benchmark Tutorial\n",
        "\n",
        "This tutorial aims to provide an insight on how the NeuroBench framework is organized and how you can use it to benchmark your own models!\n",
        "\n",
        "## About Google Speech Commands:\n",
        "Google Speech Commands is a keyword spotting task. Voice commands represent a natural and easily accessible modality for human-machine interaction. Keyword detection, in particular, is frequently employed in edge devices that operate in always-listening, wake-up situations, where it triggers more computationally demanding processes such as automatic speech recognition. Keyword spotting finds application in activating voice assistants, speech data mining, audio indexing, and phone call routing. Given that it generally operates in always-on and battery-powered edge scenarios, keyword detection represents a pertinent benchmark for energy-efficient neuromorphic solutions.\n",
        "### Dataset:\n",
        "The Google Speech Commands dataset (V2) is a commonly used dataset in assessing the performance of keyword spotting algorithms. The dataset consists of 105,829 1 second utterances of 35 different words from 2,618 distinct speakers. The data is encoded as linear 16-bit, single-channel, pulse code modulated values, at a 16 kHz sampling frequency.\n",
        "\n",
        "### Benchmark Task:\n",
        "The goal is to develop a model that trains using the designated train and validation sets, followed by an evaluation of generalization to a spearate test set. The task is a classification task.\n",
        "\n",
        "\n",
        "First we will import the relevant libraries. These include the datasets, preprocessors and accumulators. To ensure your model to be compatible with the NeuroBench framework, we will import the wrapper for snnTorch models. This wrapper will not change your model. Finally, we import the Benchmark class, which will run the benchmark and calculate your metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqtM6XbMM_hO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# import the dataloader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# import the dataset, preprocessors and accumulators you want to use\n",
        "from neurobench.datasets import SpeechCommands\n",
        "from neurobench.preprocessing import S2SProcessor\n",
        "from neurobench.accumulators import choose_max_count\n",
        "\n",
        "# import the NeuroBench wrapper to wrap your snnTorch model for usage in the NeuroBench framework\n",
        "from neurobench.models import SNNTorchModel\n",
        "# import the benchmark class\n",
        "from neurobench.benchmarks import Benchmark\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7HMjVPX7LZh"
      },
      "source": [
        "For this tutorial, we will make use of the example architecture that is included in the NeuroBench framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0yYDNRZ7UxY"
      },
      "outputs": [],
      "source": [
        "# this is the network we will be using in this tutorial\n",
        "from neurobench.examples.gsc.SNN import net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNIgTfvuOMe-"
      },
      "source": [
        "To get started, we will load our desired dataset in a dataloader:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chZeyUTAOQ6B"
      },
      "outputs": [],
      "source": [
        "test_set = SpeechCommands(path=\"data/speech_commands/\", subset=\"testing\")\n",
        "\n",
        "test_set_loader = DataLoader(test_set, batch_size=500, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTB808RoNXqL"
      },
      "source": [
        "Next, load our model and wrap it in the corresponding NeuroBench wrapper. At the time of writing this tutorial, (V1.0) snnTorch is the only supported framework, therefore, we will wrap our snnTorch model in the SNNTorchModel() wrapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4jOfnt6OeIH"
      },
      "outputs": [],
      "source": [
        "net.load_state_dict(torch.load(\"neurobench/examples/gsc/model_data/s2s_gsc_snntorch\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Wrap our net in the SNNTorchModel wrapper\n",
        "model = SNNTorchModel(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfRfdvXvOqRP"
      },
      "source": [
        "Specify the preprocessor and postprocessor want to use. These will be applied to your data before feeding into the model, and to the output spikes respectively.\n",
        "Available preprocessors and postprocessors can be found in neurobench/preprocessors and neurobench/accumulators respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GHY8vTROwzP"
      },
      "outputs": [],
      "source": [
        "preprocessors = [S2SProcessor()]\n",
        "postprocessors = [choose_max_count]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9doNsI0O0Jl"
      },
      "source": [
        "Next specify the metrics which you want to calculate. The available metrics (V1.0 release) are:\n",
        "\n",
        "static_metrics:\n",
        "*   model_size\n",
        "*   connection_sparsity\n",
        "*   frequency\n",
        "\n",
        "\n",
        "data_metrics\n",
        "*   activation_sparsity\n",
        "*   multiply_accumulates\n",
        "*   classification_accuracy\n",
        "\n",
        "More accuracy metrics are available, for which the user is recommended to consult the documentation\n",
        "\n",
        "More explanation on the metrics can be found on https://neurobench.ai/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDUczVTkPOsQ"
      },
      "outputs": [],
      "source": [
        "static_metrics = [\"model_size\"]\n",
        "data_metrics = [\"classification_accuracy\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXQYfiJpPTZb"
      },
      "source": [
        "Next, we instanciate the benchmark. We have to specify the model, the dataloader, the preprocessors, the postprocessor and the list of the static and data metrics which we want to measure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0_N96ADPeO5"
      },
      "outputs": [],
      "source": [
        "benchmark = Benchmark(model, test_set_loader, preprocessors, postprocessors, [static_metrics, data_metrics])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ytLJ-dUPp0b"
      },
      "source": [
        "Now, let's run the benchmark and print our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ldww7kiYPsU2"
      },
      "outputs": [],
      "source": [
        "results = benchmark.run()\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
