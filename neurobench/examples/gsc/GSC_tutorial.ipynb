{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGm4fad3M-Sr"
   },
   "source": [
    "# Google Speech Commands Benchmark Tutorial\n",
    "\n",
    "This tutorial aims to provide an insight on how the NeuroBench framework is organized and how you can use it to benchmark your own models!\n",
    "\n",
    "## About Google Speech Commands:\n",
    "Google Speech Commands is a keyword spotting task. Voice commands represent a natural and easily accessible modality for human-machine interaction. Keyword detection, in particular, is frequently employed in edge devices that operate in always-listening, wake-up situations, where it triggers more computationally demanding processes such as automatic speech recognition. Keyword spotting finds application in activating voice assistants, speech data mining, audio indexing, and phone call routing. Given that it generally operates in always-on and battery-powered edge scenarios, keyword detection represents a pertinent benchmark for energy-efficient neuromorphic solutions.\n",
    "### Dataset:\n",
    "The Google Speech Commands dataset (V2) is a commonly used dataset in assessing the performance of keyword spotting algorithms. The dataset consists of 105,829 1 second utterances of 35 different words from 2,618 distinct speakers. The data is encoded as linear 16-bit, single-channel, pulse code modulated values, at a 16 kHz sampling frequency.\n",
    "\n",
    "### Benchmark Task:\n",
    "The goal is to develop a model that trains using the designated train and validation sets, followed by an evaluation of generalization to a spearate test set. The task is a classification task.\n",
    "\n",
    "\n",
    "First we will import the relevant libraries. These include the datasets, preprocessors and accumulators. To ensure your model to be compatible with the NeuroBench framework, we will import the wrapper for snnTorch models. This wrapper will not change your model. Finally, we import the Benchmark class, which will run the benchmark and calculate your metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lqtM6XbMM_hO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# import the dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# import the dataset, preprocessors and accumulators you want to use\n",
    "from neurobench.datasets import SpeechCommands\n",
    "from neurobench.preprocessing import S2SProcessor\n",
    "from neurobench.accumulators import choose_max_count\n",
    "\n",
    "# import the NeuroBench wrapper to wrap your snnTorch model for usage in the NeuroBench framework\n",
    "from neurobench.models import SNNTorchModel\n",
    "# import the benchmark class\n",
    "from neurobench.benchmarks import Benchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7HMjVPX7LZh"
   },
   "source": [
    "For this tutorial, we will make use of the example architecture that is included in the NeuroBench framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "r0yYDNRZ7UxY"
   },
   "outputs": [],
   "source": [
    "# this is the network we will be using in this tutorial\n",
    "from neurobench.examples.gsc.SNN import net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNIgTfvuOMe-"
   },
   "source": [
    "To get started, we will load our desired dataset in a dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "chZeyUTAOQ6B"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/data/speech_commands/tmpy8couawl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/GSC_tutorial.ipynb Cell 6\u001B[0m line \u001B[0;36m1\n\u001B[0;32m----> <a href='vscode-notebook-cell:/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/GSC_tutorial.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001B[0m test_set \u001B[39m=\u001B[39m SpeechCommands(path\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mdata/speech_commands/\u001B[39;49m\u001B[39m\"\u001B[39;49m, subset\u001B[39m=\u001B[39;49m\u001B[39m\"\u001B[39;49m\u001B[39mtesting\u001B[39;49m\u001B[39m\"\u001B[39;49m)\n\u001B[1;32m      <a href='vscode-notebook-cell:/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/GSC_tutorial.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001B[0m test_set_loader \u001B[39m=\u001B[39m DataLoader(test_set, batch_size\u001B[39m=\u001B[39m\u001B[39m500\u001B[39m, shuffle\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/NeuroBench/algorithms_benchmarks/neurobench/datasets/__init__.py:5\u001B[0m, in \u001B[0;36mSpeechCommands\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mSpeechCommands\u001B[39m(\u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs):\n\u001B[0;32m----> 5\u001B[0m     \u001B[39mreturn\u001B[39;00m _lazy_import(\u001B[39m\"\u001B[39;49m\u001B[39mneurobench.datasets\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39m\"\u001B[39;49m\u001B[39m.speech_commands\u001B[39;49m\u001B[39m\"\u001B[39;49m, \u001B[39m\"\u001B[39;49m\u001B[39mSpeechCommands\u001B[39;49m\u001B[39m\"\u001B[39;49m)(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n",
      "File \u001B[0;32m~/NeuroBench/algorithms_benchmarks/neurobench/datasets/speech_commands.py:21\u001B[0m, in \u001B[0;36mSpeechCommands.__init__\u001B[0;34m(self, path, subset, truncate_or_pad_to_1s)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__init__\u001B[39m(\u001B[39mself\u001B[39m, path, subset:\u001B[39mstr\u001B[39m\u001B[39m=\u001B[39m\u001B[39mNone\u001B[39;00m, truncate_or_pad_to_1s\u001B[39m=\u001B[39m\u001B[39mTrue\u001B[39;00m, ):\n\u001B[1;32m     14\u001B[0m \u001B[39m    \u001B[39m\u001B[39m\"\"\" Initializes the SpeechCommands dataset.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \n\u001B[1;32m     16\u001B[0m \u001B[39m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[39m        truncate_or_pad_to_1s (bool, optional): whether to truncate or pad samples to 1s. Defaults to True.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[39m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m     SPEECHCOMMANDS\u001B[39m.\u001B[39;49m\u001B[39m__init__\u001B[39;49m(\u001B[39mself\u001B[39;49m, path, download\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m, subset\u001B[39m=\u001B[39;49msubset)\n\u001B[1;32m     22\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtruncate_or_pad_to_1s \u001B[39m=\u001B[39m truncate_or_pad_to_1s\n\u001B[1;32m     24\u001B[0m     \u001B[39m# convert labels to indices\u001B[39;00m\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/neurobench--0oLx93m-py3.10/lib/python3.10/site-packages/torchaudio/datasets/speechcommands.py:109\u001B[0m, in \u001B[0;36mSPEECHCOMMANDS.__init__\u001B[0;34m(self, root, url, folder_in_archive, download, subset)\u001B[0m\n\u001B[1;32m    107\u001B[0m         \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39misfile(archive):\n\u001B[1;32m    108\u001B[0m             checksum \u001B[39m=\u001B[39m _CHECKSUMS\u001B[39m.\u001B[39mget(url, \u001B[39mNone\u001B[39;00m)\n\u001B[0;32m--> 109\u001B[0m             download_url_to_file(url, archive, hash_prefix\u001B[39m=\u001B[39;49mchecksum)\n\u001B[1;32m    110\u001B[0m         _extract_tar(archive, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_path)\n\u001B[1;32m    111\u001B[0m \u001B[39melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/neurobench--0oLx93m-py3.10/lib/python3.10/site-packages/torch/hub.py:625\u001B[0m, in \u001B[0;36mdownload_url_to_file\u001B[0;34m(url, dst, hash_prefix, progress)\u001B[0m\n\u001B[1;32m    623\u001B[0m dst \u001B[39m=\u001B[39m os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39mexpanduser(dst)\n\u001B[1;32m    624\u001B[0m dst_dir \u001B[39m=\u001B[39m os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39mdirname(dst)\n\u001B[0;32m--> 625\u001B[0m f \u001B[39m=\u001B[39m tempfile\u001B[39m.\u001B[39;49mNamedTemporaryFile(delete\u001B[39m=\u001B[39;49m\u001B[39mFalse\u001B[39;49;00m, \u001B[39mdir\u001B[39;49m\u001B[39m=\u001B[39;49mdst_dir)\n\u001B[1;32m    627\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[39mif\u001B[39;00m hash_prefix \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/lib/python3.10/tempfile.py:698\u001B[0m, in \u001B[0;36mNamedTemporaryFile\u001B[0;34m(mode, buffering, encoding, newline, suffix, prefix, dir, delete, errors)\u001B[0m\n\u001B[1;32m    696\u001B[0m     \u001B[39mreturn\u001B[39;00m fd\n\u001B[1;32m    697\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[0;32m--> 698\u001B[0m     file \u001B[39m=\u001B[39m _io\u001B[39m.\u001B[39;49mopen(\u001B[39mdir\u001B[39;49m, mode, buffering\u001B[39m=\u001B[39;49mbuffering,\n\u001B[1;32m    699\u001B[0m                     newline\u001B[39m=\u001B[39;49mnewline, encoding\u001B[39m=\u001B[39;49mencoding, errors\u001B[39m=\u001B[39;49merrors,\n\u001B[1;32m    700\u001B[0m                     opener\u001B[39m=\u001B[39;49mopener)\n\u001B[1;32m    701\u001B[0m     \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m    702\u001B[0m         raw \u001B[39m=\u001B[39m \u001B[39mgetattr\u001B[39m(file, \u001B[39m'\u001B[39m\u001B[39mbuffer\u001B[39m\u001B[39m'\u001B[39m, file)\n",
      "File \u001B[0;32m/usr/lib/python3.10/tempfile.py:695\u001B[0m, in \u001B[0;36mNamedTemporaryFile.<locals>.opener\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    693\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mopener\u001B[39m(\u001B[39m*\u001B[39margs):\n\u001B[1;32m    694\u001B[0m     \u001B[39mnonlocal\u001B[39;00m name\n\u001B[0;32m--> 695\u001B[0m     fd, name \u001B[39m=\u001B[39m _mkstemp_inner(\u001B[39mdir\u001B[39;49m, prefix, suffix, flags, output_type)\n\u001B[1;32m    696\u001B[0m     \u001B[39mreturn\u001B[39;00m fd\n",
      "File \u001B[0;32m/usr/lib/python3.10/tempfile.py:395\u001B[0m, in \u001B[0;36m_mkstemp_inner\u001B[0;34m(dir, pre, suf, flags, output_type)\u001B[0m\n\u001B[1;32m    393\u001B[0m _sys\u001B[39m.\u001B[39maudit(\u001B[39m\"\u001B[39m\u001B[39mtempfile.mkstemp\u001B[39m\u001B[39m\"\u001B[39m, file)\n\u001B[1;32m    394\u001B[0m \u001B[39mtry\u001B[39;00m:\n\u001B[0;32m--> 395\u001B[0m     fd \u001B[39m=\u001B[39m _os\u001B[39m.\u001B[39;49mopen(file, flags, \u001B[39m0o600\u001B[39;49m)\n\u001B[1;32m    396\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mFileExistsError\u001B[39;00m:\n\u001B[1;32m    397\u001B[0m     \u001B[39mcontinue\u001B[39;00m    \u001B[39m# try again\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/korneel/NeuroBench/algorithms_benchmarks/neurobench/examples/gsc/data/speech_commands/tmpy8couawl'"
     ]
    }
   ],
   "source": [
    "test_set = SpeechCommands(path=\"data/speech_commands/\", subset=\"testing\")\n",
    "\n",
    "test_set_loader = DataLoader(test_set, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTB808RoNXqL"
   },
   "source": [
    "Next, load our model and wrap it in the corresponding NeuroBench wrapper. At the time of writing this tutorial, (V1.0) snnTorch is the only supported framework, therefore, we will wrap our snnTorch model in the SNNTorchModel() wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4jOfnt6OeIH"
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"neurobench/examples/gsc/model_data/s2s_gsc_snntorch\", map_location=torch.device('cpu')))\n",
    "\n",
    "# Wrap our net in the SNNTorchModel wrapper\n",
    "model = SNNTorchModel(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfRfdvXvOqRP"
   },
   "source": [
    "Specify the preprocessor and postprocessor want to use. These will be applied to your data before feeding into the model, and to the output spikes respectively.\n",
    "Available preprocessors and postprocessors can be found in neurobench/preprocessors and neurobench/accumulators respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GHY8vTROwzP"
   },
   "outputs": [],
   "source": [
    "preprocessors = [S2SProcessor()]\n",
    "postprocessors = [choose_max_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9doNsI0O0Jl"
   },
   "source": [
    "Next specify the metrics which you want to calculate. The available metrics (V1.0 release) are:\n",
    "\n",
    "static_metrics:\n",
    "*   model_size\n",
    "*   connection_sparsity\n",
    "*   frequency\n",
    "\n",
    "\n",
    "workload_metrics\n",
    "*   activation_sparsity\n",
    "*   multiply_accumulates\n",
    "*   classification_accuracy\n",
    "\n",
    "More accuracy metrics are available, for which the user is recommended to consult the documentation\n",
    "\n",
    "More explanation on the metrics can be found on https://neurobench.ai/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDUczVTkPOsQ"
   },
   "outputs": [],
   "source": [
    "static_metrics = [\"footprint\"]\n",
    "workload_metrics = [\"classification_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXQYfiJpPTZb"
   },
   "source": [
    "Next, we instanciate the benchmark. We have to specify the model, the dataloader, the preprocessors, the postprocessor and the list of the static and data metrics which we want to measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0_N96ADPeO5"
   },
   "outputs": [],
   "source": [
    "benchmark = Benchmark(model, test_set_loader, preprocessors, postprocessors, [static_metrics, workload_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ytLJ-dUPp0b"
   },
   "source": [
    "Now, let's run the benchmark and print our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldww7kiYPsU2"
   },
   "outputs": [],
   "source": [
    "results = benchmark.run()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
