{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGm4fad3M-Sr"
      },
      "source": [
        "# MSWC FSCIL Neurobench Tutorial\n",
        "\n",
        "This tutorial aims to provide an insight on the MSWC FSCIL NeuroBench task and present how you can use the corresponding Neurobench harness to benchmark your own models and solutions! In particular we give a tutorial to implement the prototypical network approach to both a convolutional and a recurrent spiking network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction:\n",
        "\n",
        "### About FSCIL (Few-Shot Class-Incremental Learning)\n",
        "\n",
        "Learning new tasks from a small amount of experiences while retaining knowledge of prior tasks is a hallmark of biological intelligence and a long-standing goal of general AI. It is especially a key challenge to endow edge devices with the ability to adapt to their environments and users. This benchmark thus evaluates the capacity of a learning solution to successively incorporate new classes over multiple sessions (class-incremental), with only a handful of samples from the new classes to train with (few-shot). The FSCIL task is a recently established benchmark in the computer vision domain, but it has not yet been adapted to other data modalities. \n",
        "\n",
        "### The MSWC FSCIL Neurobench Task:\n",
        "Aligning with a neuromorphic interest in temporal data modalities, this benchmark introduces a FSCIL task for streaming audio keyword classification using the large Multilingual Spoken Word Corpus (MSWC) dataset. The task is designed to be approached in two phases: pre-training and incremental learning:\n",
        "* First, for pre-training, a set of 100 words spanning 5 base languages (English, German, Catalan, French, Kinyarwanda) with 500 training samples each are made available to train an initial model. We provide here 2 pre-trained models, a convolutional and a recurrent spiking one, both trained with gradient descent on the train samples of the 100 base keywords.\n",
        "\n",
        "* Next, for incremental learning, the model undergoes 10 successive sessions to learn words from 10 new languages (Persian, Spanish, Russian, Welsh, Italian, Basque, Polish, Esparanto, Portuguese, Dutch) in a few-shot learning scenario. Each incremental session adds 10 words of the corresponding session language with only 5 training samples available per word. Here we give a tutorial for the prototypical network solution, as presented in the Neurobench paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing the Dataset\n",
        "\n",
        "The dataset is hosted on _Hugging Face_ at the following address: https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code downloads the zipped file in a _data_ folder in the neurobench repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "relative_data_folder = '../../data'\n",
        "\n",
        "# URL of the .tar.gz file\n",
        "url = 'https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset/resolve/main/mswc_fscil.tar.gz'\n",
        "\n",
        "# Download the file: It is less than 1 Gb, should be quick.\n",
        "response = requests.get(url)\n",
        "filename = os.path.join(relative_data_folder, url.split('/')[-1])\n",
        "\n",
        "with open(filename, 'wb') as file:\n",
        "    file.write(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we extract the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Open the tar file\n",
        "with tarfile.open(filename, 'r:gz') as tar:\n",
        "    # Get the total number of files within the tar archive (for the progress bar)\n",
        "    total_files = len(tar.getmembers())\n",
        "\n",
        "    # Set up the tqdm progress bar\n",
        "    with tqdm(total=total_files, unit='file', desc='Extracting files') as progress_bar:\n",
        "        for member in tar.getmembers():\n",
        "            # Extract each member\n",
        "            tar.extract(member, path=relative_data_folder)  # Replace with your desired path\n",
        "            # Update the progress bar\n",
        "            progress_bar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Benchmark Task:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, load your model that is pre-trained on the MSWC base training subset (in code: `MSWC(root=..., subset=\"base\", procedure=\"training\")`). Note that is should not have a classification layer at the end, as this will be added by the benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, convert it to a NeuroBench TorchModel:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from neurobench.models import TorchModel\n",
        "\n",
        "model = TorchModel(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Redefine the following constants as per your liking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ROOT = \"./FSCIL_subset/\" # Where the MSWC dataset is stored\n",
        "NUM_WORKERS = 8\n",
        "BATCH_SIZE = 256\n",
        "NUM_REPEATS = 5 # How many times to repeat the experiment to get aggregate statistics\n",
        "SPIKING = False\n",
        "EVAL_SHOTS = 5 # How many shots to use for evaluation\n",
        "EVAL_WAYS = 10 # How many ways to use for evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the modules required for running the benchmark:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "from neurobench.benchmarks import Benchmark\n",
        "from neurobench.datasets import MSWC\n",
        "from neurobench.datasets.MSWC_IncrementalLoader import IncrementalFewShot\n",
        "\n",
        "from mswc_fscil import to_device, squeeze, out2pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select the desired device:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if device == torch.device(\"cuda\"):\n",
        "    PIN_MEMORY = True\n",
        "else:\n",
        "    PIN_MEMORY = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the MFCC pre-processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from neurobench.preprocessing import MFCCProcessor, S2SProcessor\n",
        "\n",
        "n_fft = 512\n",
        "win_length = None\n",
        "hop_length = 240\n",
        "n_mels = 20\n",
        "n_mfcc = 20\n",
        "\n",
        "if SPIKING:\n",
        "    encode = S2SProcessor(device, transpose=False)\n",
        "    config_change = {\"sample_rate\": 48000,\n",
        "                     \"hop_length\": 240}\n",
        "    encode.configure(threshold=1.0, **config_change)\n",
        "else:\n",
        "    encode = MFCCProcessor(\n",
        "        sample_rate=48000,\n",
        "        n_mfcc=n_mfcc,\n",
        "        melkwargs={\n",
        "            \"n_fft\": n_fft,\n",
        "            \"n_mels\": n_mels,\n",
        "            \"hop_length\": hop_length,\n",
        "            \"mel_scale\": \"htk\",\n",
        "            \"f_min\": 20,\n",
        "            \"f_max\": 4000,\n",
        "        },\n",
        "        device = device\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the base training dataset to generate the prototypical representations for the base classes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_train_set = MSWC(root=ROOT, subset=\"base\", procedure=\"training\")\n",
        "train_loader = DataLoader(base_train_set, batch_size=500, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate the prototypical representations for the base classes and store them in a new linear layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if SPIKING:\n",
        "    output = model.net.snn[-1].W\n",
        "    proto_out = nn.Linear(output.weight.shape[1], 200, bias=True).to(device)\n",
        "    proto_out.weight.data = output.weight.data\n",
        "else:\n",
        "    output = model.net.output\n",
        "    proto_out = nn.Linear(512, 200, bias=True).to(device)\n",
        "    proto_out.weight.data = output.weight.data\n",
        "\n",
        "for data, target in train_loader:\n",
        "    data, target = encode((data.to(device), target.to(device)))\n",
        "    data = data.squeeze()\n",
        "    class_id = target[0]\n",
        "\n",
        "    if SPIKING:\n",
        "        features = data\n",
        "        for layer in model.net.snn[:-1]:\n",
        "            features = layer(features)\n",
        "\n",
        "        mean = torch.sum(features, dim=[0,1])/500\n",
        "        proto_out.weight.data[class_id] = 2*mean\n",
        "        proto_out.bias.data[class_id] = -torch.matmul(mean, mean.t())/features.shape[1]\n",
        "\n",
        "    else:\n",
        "        features = model.net(data, features_out=True)\n",
        "\n",
        "        mean = torch.sum(features, dim=0)/500\n",
        "        proto_out.weight.data[class_id] = 2*mean\n",
        "        proto_out.bias.data[class_id] = -torch.matmul(mean, mean.t())\n",
        "\n",
        "    del data\n",
        "    del features\n",
        "    del mean\n",
        "\n",
        "if SPIKING:\n",
        "    model.net.snn[-1].W = proto_out\n",
        "else:\n",
        "    model.net.output = proto_out\n",
        "\n",
        "del base_train_set\n",
        "del train_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, test the performance of the prototypical representations on the base test set using a Neurobench Benchmark:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Evaluation phase ###\n",
        "\n",
        "eval_model = copy.deepcopy(model)\n",
        "\n",
        "eval_accs = []\n",
        "query_accs = []\n",
        "act_sparsity = []\n",
        "syn_ops_dense = []\n",
        "syn_ops_macs = []\n",
        "syn_ops_acs = []\n",
        "\n",
        "# Get base test set for evaluation\n",
        "base_test_set = MSWC(root=ROOT, subset=\"base\", procedure=\"testing\")\n",
        "test_loader = DataLoader(base_test_set, batch_size=256, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "\n",
        "# Define an arbitrary resampling as an example of pre-processor to feed to the Benchmark object\n",
        "eval_model.net.eval()\n",
        "\n",
        "# Metrics\n",
        "static_metrics = [\"model_size\", \"connection_sparsity\"]\n",
        "workload_metrics = [\"classification_accuracy\", \"activation_sparsity\", \"synaptic_operations\"]\n",
        "\n",
        "# Define benchmark object\n",
        "benchmark_all_test = Benchmark(eval_model, metric_list=[static_metrics, workload_metrics], dataloader=test_loader, \n",
        "                    preprocessors=[to_device, encode, squeeze], postprocessors=[])\n",
        "\n",
        "benchmark_new_classes = Benchmark(eval_model, metric_list=[[],[\"classification_accuracy\"]], dataloader=test_loader,\n",
        "                    preprocessors=[to_device, encode, squeeze], postprocessors=[])\n",
        "\n",
        "# Define specific post-processing with masking on the base classes\n",
        "mask = torch.full((200,), float('inf')).to(device)\n",
        "mask[torch.arange(0,100, dtype=int)] = 0\n",
        "out_mask = lambda x: x - mask\n",
        "\n",
        "# Run session 0 benchmark on base classes\n",
        "print(f\"Session: 0\")\n",
        "\n",
        "pre_train_results = benchmark_all_test.run(postprocessors=[out_mask, F.softmax, out2pred, torch.squeeze])\n",
        "\n",
        "print(\"Base results:\", pre_train_results)\n",
        "\n",
        "eval_accs.append(pre_train_results['classification_accuracy'])\n",
        "act_sparsity.append(pre_train_results['activation_sparsity'])\n",
        "syn_ops_dense.append(pre_train_results['synaptic_operations']['Dense'])\n",
        "syn_ops_macs.append(pre_train_results['synaptic_operations']['Effective_MACs'])\n",
        "syn_ops_acs.append(pre_train_results['synaptic_operations']['Effective_ACs'])\n",
        "\n",
        "print(f\"The base accuracy is {eval_accs[-1]*100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The accuracy on the base classes using prototypical representations should be a bit lower than the accuracy of the original model. This is due to the conversion from the original backpropagation-trained readout classifier to the prototype readout classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, the dataloader for the few-shot sessions is initialized:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IncrementalFewShot Dataloader used in incremental mode to generate class-incremental sessions\n",
        "few_shot_dataloader = IncrementalFewShot(n_way=EVAL_WAYS, k_shot=EVAL_SHOTS, \n",
        "                            root = ROOT,\n",
        "                            query_shots=100,\n",
        "                            support_query_split=(100,100),\n",
        "                            samples_per_class=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, it is possible can run the incremental learning benchmark! Note however, that the code below supports both spiking and non-spiking networks (hence the flag `SPIKING` in an earlier cell). For more details on how the spiking network is constructed, please refer to [`mswc_fscil_proto.py`](./mswc_fscil_proto.py). Note that in the code below, only 'one' repeat is performed whereas in the referenced Python file, `n` repeats are executed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iteration over incremental sessions\n",
        "for session, (support, query, query_classes) in enumerate(few_shot_dataloader):\n",
        "    print(f\"Session: {session+1}\")\n",
        "\n",
        "    # Define benchmark object\n",
        "    benchmark_all_test = Benchmark(eval_model, metric_list=[static_metrics, workload_metrics], dataloader=test_loader, \n",
        "                        preprocessors=[to_device, encode, squeeze], postprocessors=[])\n",
        "\n",
        "    benchmark_new_classes = Benchmark(eval_model, metric_list=[[],[\"classification_accuracy\"]], dataloader=test_loader,\n",
        "                        preprocessors=[to_device, encode, squeeze], postprocessors=[])\n",
        "\n",
        "    ### Computing new Prototypical Weights ###\n",
        "    data = None\n",
        "    \n",
        "    for X_shot, y_shot in support:\n",
        "        if data is None:\n",
        "            data = X_shot\n",
        "            target = y_shot\n",
        "        else:\n",
        "            data = torch.cat((data,X_shot), 0)\n",
        "            target = torch.cat((target,y_shot), 0)\n",
        "\n",
        "    data, target = encode((data.to(device), target.to(device)))\n",
        "    data = data.squeeze()\n",
        "\n",
        "    if SPIKING:\n",
        "        features = eval_model.net.snn[0](data)\n",
        "        features = eval_model.net.snn[1](features)\n",
        "\n",
        "        for index, class_id in enumerate(query_classes[-EVAL_WAYS:]):\n",
        "            mean = torch.sum(features[[i*EVAL_WAYS+index for i in range(EVAL_SHOTS)]], dim=[0,1])/EVAL_SHOTS\n",
        "            eval_model.net.snn[-1].W.weight.data[class_id] = 2*mean\n",
        "            eval_model.net.snn[-1].W.bias.data[class_id] = -torch.matmul(mean, mean.t())/(features.shape[1])\n",
        "    else:\n",
        "        features = eval_model.net(data, features_out=True)\n",
        "\n",
        "        for index, class_id in enumerate(query_classes[-EVAL_WAYS:]):\n",
        "            mean = torch.sum(features[[i*EVAL_WAYS+index for i in range(EVAL_SHOTS)]], dim=0)/EVAL_SHOTS\n",
        "            eval_model.net.output.weight.data[class_id] = 2*mean\n",
        "            eval_model.net.output.bias.data[class_id] = -torch.matmul(mean, mean.t())\n",
        "\n",
        "    ### Testing phase ###\n",
        "    eval_model.net.eval()\n",
        "\n",
        "    # Define session dataloaders for query and query + base_test samples\n",
        "    query_loader = DataLoader(query, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "    \n",
        "    full_session_test_set = ConcatDataset([base_test_set, query])\n",
        "    full_session_test_loader = DataLoader(full_session_test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "\n",
        "    # Create a mask function to only consider accuracy on classes presented so far\n",
        "    session_classes = torch.cat((torch.arange(0,100, dtype=int), torch.IntTensor(query_classes))) \n",
        "    mask = torch.full((200,), float('inf')).to(device)\n",
        "    mask[session_classes] = 0\n",
        "    out_mask = lambda x: x - mask\n",
        "\n",
        "    # Run benchmark to evaluate accuracy of this specific session\n",
        "    session_results = benchmark_all_test.run(dataloader = full_session_test_loader, postprocessors=[out_mask, F.softmax, out2pred, torch.squeeze])\n",
        "    \n",
        "    print(\"Session results:\", session_results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
